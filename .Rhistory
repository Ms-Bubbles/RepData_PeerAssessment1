## set matrix
set <- function(y) {
mtx <<- y
inv <<- NULL
}
## get matrix
get <- function() mtx
## set matrix inverse
setInverse <- function(inverse) inv <<- inverse
## get matrix inverse
getInverse <- function() inv
list(set = set, get = get,
setInverse = setInverse,
getInverse = getInverse)
}
## Given a cachable matrix - compute its inverse (if needed)
cacheSolve <- function(mtx, ...) {
inv <- mtx$getInverse()
if(!is.null(inv)) {
message("getting cached inverse")
return(inv)
}
data <- mtx$get()
inv  <- solve(data)
mtx$setInverse(inv)
mtx
}
m<- makeCacheMatrix( )
m$set( matrix( c(0, 2, 2, 0 ), 2, 2))
m$get()
cacheSolve( m )
makeCacheMatrix <- function(x = matrix()) {
# Assign xinverse with NULL
xinverse <- NULL
# set() makeCacheMatrix "x" value to be like "y" and set "xinverse" value to NULL
set <- function(y) {
x <<- y
xinverse <<- NULL
}
# get() will return "x" value when called
get <- function() x
# setInverse() will set the inverse value of the matrix provided by "solve" argument
setInverse <- function(solve) xinverse <<- solve
# getInverse() will return the inverse value stored in "xinverse"
getInverse <- function() xinverse
# List of functions in makeCacheMatrix() function
list(set = set, get = get,
setInverse = setInverse,
getInverse = getInverse)
}
## The cacheSolve() function computes the inverse of the special "matrix" returned by makeCacheMatrix above.
## If the inverse has already been calculated (and the matrix has not changed), then the cacheSolve should retrieve the inverse from the cache.
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
# call getInverse Function and assign the value to "xinverse"
xinverse <- x$getInverse()
# condition checks if inverse is already set
if(!is.null(xinverse)) {
# if yes, write a message and return "xinverse"
message("getting cached data")
return(xinverse)
}
# get the value and assign it to data
data <- x$get()
# use solve to obtain the inverse of the matrix 'x'
xinverse <- solve(data, ...)
# call the function setInverse() to set the inverse value
x$setInverse(xinverse)
# return the inverse value
xinverse
}
m<- makeCacheMatrix( )
m$set( matrix( c(0, 2, 2, 0 ), 2, 2))
m$get()
cacheSolve( m )
cacheSolve( m )
makeCacheMatrix <- function(x = matrix()) {
im <- NULL
set <- function(y) {
## Reset values
x <<- y
im <<- NULL
}
get <- function() x
setInverseMatrix <- function(inverseMatrix) im <<- inverseMatrix  ## set the value into the global environment
getInverseMatrix <- function() im  ## pick up the value from the global environment
list(set = set, get = get,
setInverseMatrix = setInverseMatrix,
getInverseMatrix = getInverseMatrix)
}
## cacheSolve - This function takes the result of makeCacheMatrix as an argument and
## returns the inverse of the matrix made in makeCacheMatrix.
## It uses the makeCacheMatrix getInverseMatrix function to pull the inverse
## of the matrix from cache if it was already calculated.  Otherwise, it calculates
## the inverse of the matrix and stores the result in cache by using the
## setInverseMatrix function from makeCacheMatrix.
cacheSolve <- function(x, ...) {
im <- x$getInverseMatrix() ## see if the inverse is already available in cache
if(!is.null(im)) {
message("getting cached data")
return(im)  ## if it is available then just return it
}
## if it isn't available in cache the compute the inverse and set the result in cache
matrix <- x$get()
im <- solve(matrix)  ## compute the inverse
x$setInverseMatrix(im)
im
}
m<- makeCacheMatrix( )
m$set( matrix( c(0, 2, 2, 0 ), 2, 2))
m$get()
cacheSolve( m )
cacheSolve( m )
makeCacheMatrix <- function(x = matrix()) {
##This is an empty matrix
i <- matrix()
##Set the value of matrix.
set <- function(y) {
y <- matrix(y, nrow=2, ncol=2)
x <<- y
i <<- matrix()
}
##Get the value of matrix.
get <- function() x
setinverse <- function(x) {
i <<- solve(x)
}
##Get the value of inverse
getinverse <- function() i
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
##This function computes the inverse of the special "matrix" returned by makeCacheMatrix above with
##the requirements that the code checks if the inverse was already calculated or not.
cacheSolve <- function(x, ...) {
i <- x$getinverse()
##Case when the inverse was already calculated.
if(!is.null(i)) {
message("Getting cashed data")
return(i)
}
##Case when the inverse wasn't calculated. Calculation will be done.
data <- x$get()
i <- solve(data, ...)
x$setinverse(i)
i
}
m<- makeCacheMatrix( )
m$set( matrix( c(0, 2, 2, 0 ), 2, 2))
m$get()
cacheSolve( m )
m$set( c(0, 2, 2, 0 ))
m$get()
cacheSolve( m )
m$getInverse()
m$getinverse()
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
summaryRprof(fit)
summaryRprof(lm)
fit <- lm(y ~ x1 + x2)
Rprof()
summaryRprof()
summaryRprof(fit)
summaryRprof(fit)
set.seed(1)
rpois(5,2)
rpois(5,2)
rpois(5,2)
rpois(5,2)
?qpois
?ls
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
submit()
submit()
submit()
library(XML)
library(xlsx)
fileUrl <- "http://www.w3schools.com/xml/simple/xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
install.packages(c("evaluate", "memoise", "swirl", "yaml"))
library(xlsx)
install.packages("rJava")
library(xlsx)
library(xlsx)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile="gas.xlsx")
g_data <- read.xlsx("gas.xlsx", sheetIndex=1, colIndex=7:15, rowIndex=18:23)
g_data <- read.xlsx("gas.xlsx", sheetIndex=1)
Sys.getenv("JAVA_HOME")
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
g_data <- read.xlsx("gas.xlsx", sheetIndex=1, colIndex=7:15, rowIndex=18:23)
g_data <- read.xlsx("gas.xlsx", sheetIndex=1)
install.packages("RMySQL", type = "source")
library(RMySQL)
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ7hl=en")
htmlCode=readLines(con)
close(con)
htmlCode
library(httr)
install.packages("httr")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "0e4b2fad8f0945a986cdf03c8697d4755c14c57c")
?oauth_app
myapp <- oauth_app("github", key="Ms-Bubbles", secret= NULL)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(github, my app)
github_token <- oauth2.0_token("github", my app)
github_token <- oauth2.0_token(github, myapp)
?oauth2.0_token
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github <- oauth_endpoints("https://api.github.com/users/jtleek/repos")
github <- oauth_endpoints("https://github.com/")
github <- oauth_endpoints("github")
github_token <- oauth2.0_token(github, myapp)
myapp <- oauth_app("github", key="Ms-Bubbles", secret= "elimbic145")
github <- oauth_endpoints("github")
github_token <- oauth2.0_token(github, myapp)
myapp <- oauth_app("github", key="Ms-Bubbles", secret= "NULL")
github_token <- oauth2.0_token(github, my app)
githubtoken <- oauth2.0_token(github, my app)
githubtoken <- oauth2.0_token(github, myapp)
gtoken <- config(token = github_token)
github_token <- oauth2.0_token(github, myapp)
gtoken <- config(token = github_token)
library(httr)
?oauth_endpoints
?oauth_app
github <- oauth_endpoints("github")
myapp <- oauth_app("github",key="893ee3afb4009687d9df", secret = NULL)
library(hhtpuv)
install.packages("httpuv")
library(hhtpuv)
library(httpuv)
library(httpuv)
library(httpuv)
install.packages("httpuv")
library(httpuv)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
library("jsonlite")
json2 = jsonlite::fromJSON(toJSON(json1))
json2
req
myapp <- oauth_app("github",key="893ee3afb4009687d9df", secret = "0f63c5deed39553ccb13ccac0fbb672f7681e416")
req
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)
jsonData
jsonData[1, 1:4]
jsonData[2, 1:4]
head(jsonData)
summary(jsonData)
jsonData$created_at
jsonData[1, 1:5]
jsonData[5, created_at]
jsonData[5, ]
jsonData$"name"=="datasharing"
dim(jsonData)
class(jsonData)
jsonData["datasharing", ]
names(jsonData)
jsonData["name": "datasharing","created_at"]
jsonData["datasharing","created_at"]
jsonData[datasharing,created_at]
jsonData[datasharing,"created_at"]
jsonData[name == "datasharing",]
jsonData[== "datasharing",]
jsonData["datasharing",]
jsonData$name == "datasharing"
jsonData$name ='datasharing'
ds <- jsonData$name ='datasharing'
ds <- jsonData$name
ds
ds$created_at
jsonData
head(jsonData)
install.packages("sqldf")
setwd("./UCI HAR Dataset")
##preparing descriptive labels to column names
header <- read.table("./features.txt")
header <- as.factor(header$V2)
testData <- read.table("./test/X_test.txt")
##assigning descriptive labels to column names
colnames(testData) <- header
testLabels <- read.table("./test/y_test.txt")
colnames(testLabels)<- c("Labels")
testSubjects <- read.table("./test/subject_test.txt")
colnames(testSubjects)<- c("SubjectIDs")
test <- cbind(testSubjects, testLabels, testData)
trainData <- read.table("./train/X_train.txt")
##assigning descriptive labels to column names
colnames(trainData) <- header
trainLabels <- read.table("./train/y_train.txt")
colnames(trainLabels)<- c("Labels")
trainSubjects <- read.table("./train/subject_train.txt")
colnames(trainSubjects)<- c("SubjectIDs")
train <- cbind(trainSubjects, trainLabels, trainData)
##merge the two data sets
bindData <- rbind(test, train)
labels <- names(bindData)
sel_mean <- grep("-mean()", labels, fixed = TRUE)
sel_std <- grep("-std()", labels, fixed = TRUE)
means <- bindData[,sel_mean]
stds <- bindData[,sel_std]
cleanData <- cbind(SubjectIDs = bindData$SubjectIDs, Labels = bindData$Labels, means, stds)
##assigning descriptive activity names to variables
cleanData$Labels[cleanData$Labels =="1"] <-"WALKING"
cleanData$Labels[cleanData$Labels =="2"] <-"WALKING_UPSTAIRS"
cleanData$Labels[cleanData$Labels =="3"] <-"WALKING_DOWNSTAIRS"
cleanData$Labels[cleanData$Labels =="4"] <-"SITTING"
cleanData$Labels[cleanData$Labels =="5"] <-"STANDING"
cleanData$Labels[cleanData$Labels =="6"] <-"LAYING"
##Point 5: Creating independent tidy data set with the average of each variable for each activity and each subject
tidyData <- aggregate(cleanData[,3:ncol(cleanData)], list(SubjectIDs=cleanData$SubjectIDs, ActivityLabels=cleanData$Labels), mean)
##Sorting the data based on the subject ids
tidyData <- tidyData[order(tidyData$SubjectIDs, decreasing=FALSE),]
tidyData$SubjectIDs <- as.factor(tidyData$SubjectIDs)
##Creating an output file with the tidy data
write.table(tidyData, file="./TidyData.txt", sep="\t", row.names=FALSE)
setwd("./RWorking Directory/UCI HAR Dataset")
##preparing descriptive labels to column names
header <- read.table("./features.txt")
header <- as.factor(header$V2)
testData <- read.table("./test/X_test.txt")
##assigning descriptive labels to column names
colnames(testData) <- header
testLabels <- read.table("./test/y_test.txt")
colnames(testLabels)<- c("Labels")
testSubjects <- read.table("./test/subject_test.txt")
colnames(testSubjects)<- c("SubjectIDs")
test <- cbind(testSubjects, testLabels, testData)
trainData <- read.table("./train/X_train.txt")
##assigning descriptive labels to column names
colnames(trainData) <- header
trainLabels <- read.table("./train/y_train.txt")
colnames(trainLabels)<- c("Labels")
trainSubjects <- read.table("./train/subject_train.txt")
colnames(trainSubjects)<- c("SubjectIDs")
train <- cbind(trainSubjects, trainLabels, trainData)
##merge the two data sets
bindData <- rbind(test, train)
labels <- names(bindData)
sel_mean <- grep("-mean()", labels, fixed = TRUE)
sel_std <- grep("-std()", labels, fixed = TRUE)
means <- bindData[,sel_mean]
stds <- bindData[,sel_std]
cleanData <- cbind(SubjectIDs = bindData$SubjectIDs, Labels = bindData$Labels, means, stds)
##assigning descriptive activity names to variables
cleanData$Labels[cleanData$Labels =="1"] <-"WALKING"
cleanData$Labels[cleanData$Labels =="2"] <-"WALKING_UPSTAIRS"
cleanData$Labels[cleanData$Labels =="3"] <-"WALKING_DOWNSTAIRS"
cleanData$Labels[cleanData$Labels =="4"] <-"SITTING"
cleanData$Labels[cleanData$Labels =="5"] <-"STANDING"
cleanData$Labels[cleanData$Labels =="6"] <-"LAYING"
##Point 5: Creating independent tidy data set with the average of each variable for each activity and each subject
tidyData <- aggregate(cleanData[,3:ncol(cleanData)], list(SubjectIDs=cleanData$SubjectIDs, ActivityLabels=cleanData$Labels), mean)
##Sorting the data based on the subject ids
tidyData <- tidyData[order(tidyData$SubjectIDs, decreasing=FALSE),]
tidyData$SubjectIDs <- as.factor(tidyData$SubjectIDs)
##Creating an output file with the tidy data
write.table(tidyData, file="./TidyData.txt", sep="\t", row.names=FALSE)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
y <- x*w
y
mean(y)
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
beta1 <- cor(y, x)*sd(y)/sd(x)
beta1
coef(lm(y~x))
data(mtcars)
summary(mtcars)
coef(lm(mtcars$mpg~mtcars$weight))
coef(lm(mtcars$mpg~mtcars$wt))
1.5*0.4
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
xn <- (x - mean(x)/sd(x))
xn
xn[2]
xn[1]
xn <- (x - mean(x))/sd(x)
xn[1]
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
coef(lm(y~x))
xn <- (x - mean(x))/sd(x)
yn <- (y - mean(y))/sd(y)
coef(lm(y~x))
coef(lm(yn~xn))
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mean(x)
xw <- x*w
xw
mean(xw)
mean <- xw/w
mean
sum(xw)
sum(xw)/sum(w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
beta1 <- sum(y*x)/sum(x^2)
beta1
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
coef(lm(y~x))
mean(x)
"PA1_template.Rmd1"
===============================
###1. Loading and Pre-preparing data
Following code loads the data :
```{r, echo=TRUE}
setwd("D:/RWorking Directory/RepData_PeerAssessment1")
data <- read.csv("activity.csv")
```
And transforms it into a suitable format:
```{r, echo=TRUE}
steps_sum <- tapply(data$steps, data$date, sum)
steps_sum <- as.data.frame(steps_sum)
steps_sum$steps_sum <- as.numeric(steps_sum$steps_sum)
```
###2. What is mean total number of steps taken per day?
Following chunk of code creates a histogram of total numbers of steps taken per day:
```{r, echo=TRUE}
hist(steps_sum$steps_sum, xlab = "Total number of steps made per day", main= "Histogram of total steps made per day", cex.main = 1.2, cex.lab=0.8, font.lab = 3)
```
Following chunk of code counts the mean and median of the sum of steps taken each day, i.e: median of sum of steps taken on day 1, day 2... etc. and similarly with mean. NA values were ignored.
```{r, echo=TRUE}
mean(steps_sum$steps_sum, na.rm=TRUE)
median(steps_sum$steps_sum, na.rm=TRUE)
```
###3. What is the average daily activity pattern?
Creating a time series plot of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis):
```{r, echo=TRUE}
steps_averaged <- tapply(data$steps, data$interval, mean, na.rm=TRUE)
steps_averaged <- as.data.frame(steps_averaged)
steps_averaged$steps_averaged <- as.numeric(steps_averaged$steps_averaged)
plot(steps_averaged$steps_averaged, type="l", main="Steps averaged across all days based on intervals", xlab="Intervals", ylab="Steps Averaged", cex.main = 1.2, cex.lab=0.8, font.lab = 3)
```
Finding interval corresponding to the highest steps average:
```{r, echo=TRUE}
steps_averaged$interval <- rownames(steps_averaged)
steps_averaged[which.max(steps_averaged$steps_averaged),]
```
###4. Imputing missing values
How many missing values are there in the data set (number of rows)
```{r, echo=TRUE}
nrow(data[!complete.cases(data),])
```
Exchanging missing values and creating a new data set with the missing values excganged:
```{r}
nd <- merge(data, steps_averaged, by="interval")
nd <- nd[order(nd$date),]
nd$steps[is.na(nd$steps)] <- nd$steps_averaged[is.na(nd$steps)]
```
Creating a histogram of the total number of steps taken per day:
```{r}
steps_sum2 <- tapply(nd$steps, nd$date, sum)
steps_sum2 <- as.data.frame(steps_sum2)
steps_sum2$steps_sum2 <- as.numeric(steps_sum2$steps_sum2)
hist(steps_sum2$steps_sum2, xlab = "Number of steps made per day", main= "Histogram of total steps made per day (NAs exluded)", cex.main = 1.2, cex.lab=0.8, font.lab=3)
```
Comparing two outcomes: with NAs and w/o NAs based on mean and median
```{r}
mean_na <- mean(steps_sum$steps_sum, na.rm=TRUE)
median_na <- median(steps_sum$steps_sum, na.rm=TRUE)
mean_nar <- mean(steps_sum2$steps_sum2, na.rm=TRUE)
median_nar <- median(steps_sum2$steps_sum2, na.rm=TRUE)
comp_table <- matrix(c(mean_na, median_na, mean_nar, median_nar), ncol=2)
rownames(comp_table) <- c("Mean", "Median")
colnames(comp_table) <- c("With NAs", "W/o NAs")
comp_table
```
###5. Are there differences in activity patterns between weekdays and weekends?
Create a new factor variable with two level information on the dates weekday or weekend:
```{r}
Sys.setlocale("LC_TIME", "English")
nd$day <- as.Date(nd$date)
nd$day <- weekdays(nd$day, abbreviate=FALSE)
nd$day[nd$day %in% c("Saturday", "Sunday")] <- "weekend"
nd$day[nd$day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")] <- "weekday"
```
```{r}
weekdays <- nd[nd$day=="weekday",]
weekends <- nd[nd$day=="weekend",]
wd <- as.data.frame(tapply(weekdays$steps, weekdays$interval, mean, na.rm=TRUE))
we <- as.data.frame(tapply(weekends$steps, weekends$interval, mean, na.rm=TRUE))
wd$intervals <- rownames(wd)
we$intervals <- rownames(we)
colnames(wd) <- c("steps", "intervals")
colnames(we) <- c("steps", "intervals")
par(mfrow=c(2,1))
plot(we$steps, type="l", main = "Weekends", cex.lab=0.8, cex.axis=0.5, font.lab=3, cex.main=1, xlab="Intervals", ylab="Number of steps", col="blue")
plot(wd$steps, type="l", main = "Weekdays", cex.lab=0.8, cex.axis=0.5, font.lab=3, cex.main=1, xlab="Intervals", ylab="Number of steps", col="blue")
```
Creating a html file based on the above:
```{r, echo=FALSE}
library(knitr)
knit2html("PA1_template.Rmd")
```
